{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "from meta_model.utils import ndcg_sim, ndcg, custom_sim\n",
    "import matplotlib.pyplot as plt\n",
    "from metrics import base_metrics\n",
    "sys.path.append(\"meta_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 35, 49)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "9, 35, 49, 186, 188"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n",
      "1121\n",
      "41004\n",
      "987\n",
      "40978\n"
     ]
    }
   ],
   "source": [
    "for filename in os.listdir(\"meta_dataset_creation/data/benchmark_results_prev/fasterpam/original/scores/\"):\n",
    "    data_id = filename.split(\".\")[0]\n",
    "    with open(f\"meta_dataset_creation/data/benchmark_results_prev/fasterpam/original/scores/{data_id}.pickle\", \"rb\") as f:\n",
    "        scores = pickle.load(f)\n",
    "    if max([max([obj['score'] for obj in scores[p][\"acc\"]]) for p in scores]) - max([obj['score'] for obj in scores[\"euclidean_hamming\"][\"acc\"]]) > 0.2:\n",
    "        print(data_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_id = 1121\n",
    "with open(f\"datasets/mixed/original/{data_id}.pickle\", \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "with open(f\"meta_dataset_creation/data/benchmark_results_prev/fasterpam/original/scores/{data_id}.pickle\", \"rb\") as f:\n",
    "    scores = pickle.load(f)\n",
    "\n",
    "eval_metric = \"sil\"\n",
    "baseline_pairs = 'euclidean_hamming'\n",
    "best_pair = sorted(\n",
    "    scores.keys(),\n",
    "    key= lambda p: -max([obj['score'] for obj in scores[p][eval_metric] \\\n",
    "        if 0.1 <= obj['params']['alpha'] <= 0.9])\n",
    ")[0]\n",
    "colors = {baseline_pairs:\"red\", best_pair:\"green\"}\n",
    "plt.figure(figsize=(4, 3))\n",
    "for sim_pair in [baseline_pairs, best_pair]:\n",
    "    y = {}\n",
    "    for obj in scores[sim_pair][eval_metric]:\n",
    "        if 0.1 <= obj['params']['alpha'] <= 0.9:\n",
    "            n_clusters = obj['params']['n_clusters']\n",
    "            if n_clusters not in y:\n",
    "                y[n_clusters] = obj['score']\n",
    "            else:\n",
    "                y[n_clusters] = max(y[n_clusters], obj['score'])\n",
    "    plt.plot(y.keys(), y.values(), \"--\", c=colors[sim_pair], linewidth=0.5)\n",
    "    plt.scatter(\n",
    "        y.keys(), y.values(), c=colors[sim_pair],\n",
    "        s=[20 if n_clusters!=len(set(data[\"y\"])) else 40 for n_clusters in y.keys()],\n",
    "        edgecolor=\"black\",\n",
    "        linewidth=[0 if n_clusters!=len(set(data[\"y\"])) else 1 for n_clusters in y.keys()],\n",
    "        zorder=2\n",
    "    )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homedir/adiop/workspace/simrec-for-mdc/venv/lib/python3.8/site-packages/sklearn/manifold/_mds.py:298: FutureWarning: The default value of `normalized_stress` will change to `'auto'` in version 1.4. To suppress this warning, manually set the value of `normalized_stress`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homedir/adiop/workspace/simrec-for-mdc/venv/lib/python3.8/site-packages/sklearn/manifold/_mds.py:298: FutureWarning: The default value of `normalized_stress` will change to `'auto'` in version 1.4. To suppress this warning, manually set the value of `normalized_stress`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import minmax_scale, StandardScaler, normalize\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE, MDS\n",
    "from clustering_algorithms import kmedoids\n",
    "from sklearn.preprocessing import OneHotEncoder, minmax_scale\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "for i, sim_pair in enumerate([baseline_pairs, best_pair]):\n",
    "    Dnum = base_metrics.get_metric(sim_pair.split(\"_\")[0]).fit(data[\"Xnum\"]).pairwise(minmax_scale(data[\"Xnum\"]))\n",
    "    if sim_pair.split(\"_\")[1] in base_metrics.get_available_metrics(data_type=\"categorical\"):\n",
    "        Dcat = base_metrics.get_metric(sim_pair.split(\"_\")[1]).fit(data[\"Xcat\"]).pairwise(data[\"Xcat\"])\n",
    "    else:\n",
    "        enc = OneHotEncoder(handle_unknown='ignore')\n",
    "        Xdummy = enc.fit_transform(data[\"Xcat\"]).toarray()\n",
    "        Dcat = base_metrics.get_metric(sim_pair.split(\"_\")[1]).fit(Xdummy).pairwise(Xdummy)\n",
    "    ind = np.argmax([obj['score'] for obj in scores[sim_pair][eval_metric] if 0.1 <= obj['params']['alpha'] <= 0.9])\n",
    "    alpha = [obj for obj in scores[sim_pair][eval_metric] if 0.1 <= obj['params']['alpha'] <= 0.9][ind]['params']['alpha']\n",
    "    print(alpha)\n",
    "    n_clusters = [obj for obj in scores[sim_pair][eval_metric] if 0.1 <= obj['params']['alpha'] <= 0.9][ind]['params']['n_clusters']\n",
    "    D = (1-alpha)*Dnum + alpha*Dcat\n",
    "    # X = TSNE(n_components=2, metric=\"precomputed\", init=\"random\",\n",
    "    #     learning_rate=\"auto\", n_jobs=-1).fit_transform(D)\n",
    "    X = MDS(n_components=2, dissimilarity=\"precomputed\", n_jobs=-1).fit_transform(D)\n",
    "    clusters = kmedoids(Dnum, Dcat, alpha, n_clusters, method=\"fasterpam\")\n",
    "    plt.subplot(1, 2, i+1)\n",
    "    plt.scatter(X[:,0], X[:, 1], c=data[\"y\"], s=10) #, data[\"y\"]\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4704, 24)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Xcat\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_id = 41004\n",
    "with open(f\"datasets/mixed/original/{data_id}.pickle\", \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "with open(f\"meta_dataset_creation/data/benchmark_results_prev/fasterpam/original/scores/{data_id}.pickle\", \"rb\") as f:\n",
    "    scores = pickle.load(f)\n",
    "\n",
    "eval_metric = \"acc\"\n",
    "baseline_pairs = 'euclidean_hamming'\n",
    "best_pair = sorted(\n",
    "    scores.keys(),\n",
    "    key= lambda p: -max([obj['score'] for obj in scores[p][eval_metric]])\n",
    ")[0]\n",
    "colors = {baseline_pairs:\"red\", best_pair:\"green\"}\n",
    "plt.figure(figsize=(4, 3))\n",
    "for sim_pair in [baseline_pairs, best_pair]:\n",
    "    y = {}\n",
    "    for obj in scores[sim_pair][eval_metric]:\n",
    "        alpha = obj['params']['alpha']\n",
    "        if alpha not in y:\n",
    "            y[alpha] = obj['score']\n",
    "        else:\n",
    "            y[alpha] = max(y[alpha], obj['score'])\n",
    "    plt.plot(y.keys(), y.values(), \"--o\", c=colors[sim_pair], markersize=3, linewidth=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homedir/adiop/workspace/simrec-for-mdc/venv/lib/python3.8/site-packages/sklearn/manifold/_mds.py:298: FutureWarning: The default value of `normalized_stress` will change to `'auto'` in version 1.4. To suppress this warning, manually set the value of `normalized_stress`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[122], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m D \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39malpha)\u001b[38;5;241m*\u001b[39mDnum \u001b[38;5;241m+\u001b[39m alpha\u001b[38;5;241m*\u001b[39mDcat\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# X = TSNE(n_components=2, metric=\"precomputed\", init=\"random\",\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m#     learning_rate=\"auto\", n_jobs=-1).fit_transform(D)\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mMDS\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_components\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdissimilarity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprecomputed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mD\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m clusters \u001b[38;5;241m=\u001b[39m kmedoids(Dnum, Dcat, alpha, n_clusters, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfasterpam\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     19\u001b[0m plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/workspace/simrec-for-mdc/venv/lib/python3.8/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/simrec-for-mdc/venv/lib/python3.8/site-packages/sklearn/manifold/_mds.py:613\u001b[0m, in \u001b[0;36mMDS.fit_transform\u001b[0;34m(self, X, y, init)\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdissimilarity \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meuclidean\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    611\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdissimilarity_matrix_ \u001b[38;5;241m=\u001b[39m euclidean_distances(X)\n\u001b[0;32m--> 613\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstress_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter_ \u001b[38;5;241m=\u001b[39m \u001b[43msmacof\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    614\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdissimilarity_matrix_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    615\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    616\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_components\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_components\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    617\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    618\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    619\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    620\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    621\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    623\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    624\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_n_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    625\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnormalized_stress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalized_stress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    626\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_\n",
      "File \u001b[0;32m~/workspace/simrec-for-mdc/venv/lib/python3.8/site-packages/sklearn/manifold/_mds.py:346\u001b[0m, in \u001b[0;36msmacof\u001b[0;34m(dissimilarities, metric, n_components, init, n_init, n_jobs, max_iter, verbose, eps, random_state, return_n_iter, normalized_stress)\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    345\u001b[0m     seeds \u001b[38;5;241m=\u001b[39m random_state\u001b[38;5;241m.\u001b[39mrandint(np\u001b[38;5;241m.\u001b[39miinfo(np\u001b[38;5;241m.\u001b[39mint32)\u001b[38;5;241m.\u001b[39mmax, size\u001b[38;5;241m=\u001b[39mn_init)\n\u001b[0;32m--> 346\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_smacof_single\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdissimilarities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_components\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_components\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m            \u001b[49m\u001b[43minit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m            \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m            \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnormalized_stress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnormalized_stress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mseeds\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    360\u001b[0m     positions, stress, n_iters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mresults)\n\u001b[1;32m    361\u001b[0m     best \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmin(stress)\n",
      "File \u001b[0;32m~/workspace/simrec-for-mdc/venv/lib/python3.8/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/simrec-for-mdc/venv/lib/python3.8/site-packages/joblib/parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1946\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   1947\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   1948\u001b[0m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[1;32m   1949\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   1950\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1952\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/simrec-for-mdc/venv/lib/python3.8/site-packages/joblib/parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1592\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1594\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1595\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1597\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1598\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1599\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1600\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1601\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/workspace/simrec-for-mdc/venv/lib/python3.8/site-packages/joblib/parallel.py:1707\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1702\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1703\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1704\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1705\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1706\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1707\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1708\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1710\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1711\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1712\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x400 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "for i, sim_pair in enumerate([baseline_pairs, best_pair]):\n",
    "    Dnum = base_metrics.get_metric(sim_pair.split(\"_\")[0]).fit(data[\"Xnum\"]).pairwise(minmax_scale(data[\"Xnum\"]), n_jobs=-1)\n",
    "    if sim_pair.split(\"_\")[1] in base_metrics.get_available_metrics(data_type=\"categorical\"):\n",
    "        Dcat = base_metrics.get_metric(sim_pair.split(\"_\")[1]).fit(data[\"Xcat\"]).pairwise(data[\"Xcat\"], n_jobs=-1)\n",
    "    else:\n",
    "        enc = OneHotEncoder(handle_unknown='ignore')\n",
    "        Xdummy = enc.fit_transform(data[\"Xcat\"]).toarray()\n",
    "        Dcat = base_metrics.get_metric(sim_pair.split(\"_\")[1]).fit(Xdummy).pairwise(Xdummy, n_jobs=-1)\n",
    "    ind = np.argmax([obj['score'] for obj in scores[sim_pair][eval_metric]])\n",
    "    alpha = scores[sim_pair][eval_metric][ind]['params']['alpha']\n",
    "    print(alpha)\n",
    "    n_clusters = scores[sim_pair][eval_metric][ind]['params']['n_clusters']\n",
    "    D = (1-alpha)*Dnum + alpha*Dcat\n",
    "    # X = TSNE(n_components=2, metric=\"precomputed\", init=\"random\",\n",
    "    #     learning_rate=\"auto\", n_jobs=-1).fit_transform(D)\n",
    "    X = MDS(n_components=2, dissimilarity=\"precomputed\", n_jobs=-1).fit_transform(D)\n",
    "    clusters = kmedoids(Dnum, Dcat, alpha, n_clusters, method=\"fasterpam\")\n",
    "    plt.subplot(1, 2, i+1)\n",
    "    plt.scatter(X[:,0], X[:, 1], c=data[\"y\"], s=10, alpha=0.7) #, data[\"y\"]\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import minmax_scale, StandardScaler, normalize\n",
    "# from sklearn.decomposition import PCA\n",
    "# from sklearn.manifold import TSNE, MDS\n",
    "# from scipy.stats import wasserstein_distance\n",
    "# import matplotlib.pyplot as plt\n",
    "# df1 = pd.read_csv(\"meta_dataset_creation/data/meta_features/original/if_meta_features.csv\", index_col=\"id\")\n",
    "# df2 = pd.read_csv(\"meta_dataset_creation/data/meta_features/from_numeric/if_meta_features.csv\", index_col=\"id\")\n",
    "\n",
    "# meta_X1 = df1.to_numpy()\n",
    "# meta_X2 = df2.to_numpy()\n",
    "# # sc = StandardScaler().fit(meta_X1)\n",
    "# scaled_matrix1 = meta_X1/meta_X1.shape[1] #sc.transform(meta_X1)\n",
    "# scaled_matrix2 = meta_X2/meta_X2.shape[1] #sc.transform(meta_X2)\n",
    "# print(\"Number of meta features1:\", meta_X1.shape[1])\n",
    "# print(\"Number of instances1:\", meta_X1.shape[0])\n",
    "# print(\"Number of meta features2:\", meta_X2.shape[1])\n",
    "# print(\"Number of instances2:\", meta_X2.shape[0])\n",
    "# X = TSNE(n_components=2, metric=wasserstein_distance, init=\"pca\",\n",
    "#     learning_rate=\"auto\", n_jobs=-1).fit_transform(np.concatenate((scaled_matrix1, scaled_matrix2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(5, 5))\n",
    "# plt.scatter(\n",
    "#     X[:meta_X1.shape[0], 0], X[:meta_X1.shape[0], 1], s=20,\n",
    "#     alpha=0.7,\n",
    "#     linewidth=0,\n",
    "#     c=\"green\"\n",
    "# )\n",
    "# indices = np.random.choice(meta_X2.shape[0], size=500, replace=False) + meta_X1.shape[0]\n",
    "# plt.scatter(\n",
    "#     X[indices, 0], X[indices, 1], s=20,\n",
    "#     alpha=0.7,\n",
    "#     linewidth=0,\n",
    "#     c=\"red\"\n",
    "# )\n",
    "# plt.xticks([])\n",
    "# plt.yticks([])\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = np.array([1, 0.95, 0.9, 0.8, 0.7])\n",
    "y2 = np.array([0.9, 1, 0.95, 0.8, 0.7])\n",
    "ndcg(y1**4, y2**4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_results = {}\n",
    "benchmark_results_dir = \"meta_dataset_creation/data/benchmark_results/\"\n",
    "clustering_algorithms = os.listdir(benchmark_results_dir)\n",
    "clustering_algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for algorithm in clustering_algorithms:\n",
    "    print(algorithm)\n",
    "    benchmark_results[algorithm] = {}\n",
    "    for name in os.listdir(os.path.join(benchmark_results_dir, algorithm)):\n",
    "        print(\"\\t\", name)\n",
    "        benchmark_results[algorithm][name] = {}\n",
    "        folder_path = os.path.join(benchmark_results_dir, algorithm, name)\n",
    "        scores_dir = os.path.join(folder_path, \"scores/\")\n",
    "        for filename in os.listdir(scores_dir):\n",
    "            data_id = filename.split('.')[0]\n",
    "            with open(os.path.join(scores_dir, filename), \"rb\") as f:\n",
    "                result = pickle.load(f)\n",
    "            for sim_pair in result:\n",
    "                for eval_metric in result[sim_pair]:\n",
    "                    if eval_metric not in benchmark_results[algorithm][name]:\n",
    "                        benchmark_results[algorithm][name][eval_metric] = {}\n",
    "                    if data_id not in benchmark_results[algorithm][name][eval_metric]:\n",
    "                        benchmark_results[algorithm][name][eval_metric][data_id] = {}\n",
    "                    benchmark_results[algorithm][name][eval_metric][data_id][sim_pair] = \\\n",
    "                        max([v[\"score\"] for v in result[sim_pair][eval_metric]])\n",
    "        for eval_metric in benchmark_results[algorithm][name]:\n",
    "            benchmark_results[algorithm][name][eval_metric] = \\\n",
    "                pd.DataFrame.from_dict(benchmark_results[algorithm][name][eval_metric], orient='index')\n",
    "            benchmark_results[algorithm][name][eval_metric] = \\\n",
    "                benchmark_results[algorithm][name][eval_metric].fillna(-1)\n",
    "            benchmark_results[algorithm][name][eval_metric] = \\\n",
    "                benchmark_results[algorithm][name][eval_metric].replace(-1, -10)\n",
    "            print(eval_metric, benchmark_results[algorithm][name][eval_metric].shape)\n",
    "        if len(benchmark_results[algorithm][name]) > 0:\n",
    "            print()\n",
    "            max_ = benchmark_results[algorithm][name][\"acc\"].max(axis=1)\n",
    "            for eval_metric in [\"acc\", \"ari\", \"purity\"]:\n",
    "                benchmark_results[algorithm][name][eval_metric] = benchmark_results[algorithm][name][eval_metric][max_ >= 0.7]\n",
    "                print(eval_metric, benchmark_results[algorithm][name][eval_metric].shape)\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm = 'kprototypes'\n",
    "eval_metric = 'acc'\n",
    "benchmark_results[algorithm][\"original\"][eval_metric].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_results[algorithm][\"from_numeric\"][eval_metric].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import minmax_scale, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy import stats\n",
    "mixed_meta_df = pd.read_csv(\"meta_dataset_creation/data/meta_features/original/meta_features.csv\", index_col=\"id\").drop_duplicates()\n",
    "mixed_meta_df.index = mixed_meta_df.index.astype(str)\n",
    "print(\"Number of meta features:\", mixed_meta_df.shape[1])\n",
    "print(\"Number of instances:\", mixed_meta_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_meta_df = pd.read_csv(\"meta_dataset_creation/data/meta_features/from_numeric/meta_features.csv\", index_col=\"id\").drop_duplicates()\n",
    "numeric_meta_df.index = numeric_meta_df.index.astype(str)\n",
    "print(\"Number of meta features:\", numeric_meta_df.shape[1])\n",
    "print(\"Number of instances:\", numeric_meta_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import pairwise_distances\n",
    "index = benchmark_results[algorithm][\"original\"][eval_metric].index\n",
    "mixed_Y = benchmark_results[algorithm][\"original\"][eval_metric][index.isin(mixed_meta_df.index)].to_numpy()\n",
    "mixed_Yn = np.array([y/max(y) for y in mixed_Y])\n",
    "mixed_Yn[mixed_Yn>0] **= 4\n",
    "mixed_Yn[mixed_Yn<0] = -1\n",
    "\n",
    "index = benchmark_results[algorithm][\"from_numeric\"][eval_metric].index\n",
    "numeric_Y = benchmark_results[algorithm][\"from_numeric\"][eval_metric][index.isin(numeric_meta_df.index)].to_numpy()\n",
    "numeric_Yn = np.array([y/max(y) for y in numeric_Y])\n",
    "numeric_Yn[numeric_Yn>0] **= 4\n",
    "numeric_Yn[numeric_Yn<0] = -1\n",
    "\n",
    "# sim_matrix = pairwise_distances(mixed_Yn, metric=lambda y1,y2: ndcg_sim(y1,y2,p=5), n_jobs=-1)\n",
    "sim_matrix = pairwise_distances(np.concatenate((mixed_Yn, numeric_Yn)), metric=lambda y1,y2: ndcg_sim(y1,y2,p=5), n_jobs=-1)\n",
    "# sim_matrix = pairwise_distances(Y, metric=lambda y1,y2: custom_sim(y1,y2), n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.fill_diagonal(sim_matrix, 0)\n",
    "# print(mixed_Yn.shape)\n",
    "# for i, x in enumerate(np.argsort(-sim_matrix[:mixed_Yn.shape[0]], axis=1)[:, :10]):\n",
    "#     print(x, sim_matrix[i][x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = benchmark_results[algorithm][\"original\"][eval_metric].index\n",
    "mixed_X = mixed_meta_df.loc[[i for i in index if i in mixed_meta_df.index]].to_numpy()\n",
    "\n",
    "index = benchmark_results[algorithm][\"from_numeric\"][eval_metric].index\n",
    "numeric_X = numeric_meta_df.loc[[i for i in index if i in numeric_meta_df.index]].to_numpy()\n",
    "sc = StandardScaler().fit(np.concatenate((mixed_X, numeric_X))) #StandardScaler().fit(mixed_X) #\n",
    "mixed_X = sc.transform(mixed_X) # mixed_X/mixed_X.shape[1] #\n",
    "numeric_X = sc.transform(numeric_X) # numeric_X/numeric_X.shape[1] #\n",
    "\n",
    "mixed_X.shape, numeric_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate((mixed_X, numeric_X))\n",
    "Y = np.concatenate((mixed_Y, numeric_Y))\n",
    "Yn = np.concatenate((mixed_Yn, numeric_Yn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "D = pairwise_distances(X, n_jobs=-1)\n",
    "np.fill_diagonal(D, np.inf)\n",
    "ndcg_nn_euclidean = []\n",
    "for i, dist_vec in enumerate(D):\n",
    "    nearest_neighbors = [j for j in np.argsort(dist_vec) if j != i][:k]\n",
    "    ndcg_nn_euclidean.append(np.mean(sim_matrix[i][nearest_neighbors]))\n",
    "\n",
    "# D = pairwise_distances(np.concatenate((mixed_X, numeric_X)), metric=wasserstein_distance, n_jobs=-1)\n",
    "# np.fill_diagonal(D, np.inf)\n",
    "# ndcg_nn_wasserstein = []\n",
    "# for i, dist_vec in enumerate(D):\n",
    "#     nearest_neighbors = [j for j in np.argsort(dist_vec) if j != i][:k]\n",
    "#     ndcg_nn_wasserstein.append(np.mean(sim_matrix[i][nearest_neighbors]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(ndcg_nn_euclidean, 10, density=True, alpha=0.7)\n",
    "# plt.hist(ndcg_nn_wasserstein, 10, density=True, alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D = pairwise_distances(X)\n",
    "# np.fill_diagonal(D, np.inf)\n",
    "nearest_neighbors_distance = np.sort(D, axis=1)[:, :5]\n",
    "nearest_neighbors_distance = np.mean(nearest_neighbors_distance, axis=1)\n",
    "median_distance = np.quantile(nearest_neighbors_distance, 0.5)\n",
    "plt.hist(nearest_neighbors_distance, 50, density=True)\n",
    "# plt.hist(nearest_neighbors_distance[:mixed_X.shape[0]], 30, density=True)\n",
    "plt.axvline(median_distance, color=\"red\")\n",
    "plt.show()\n",
    "selected_datasets = [i for i in range(mixed_X.shape[0])] # if nearest_neighbors_distance[i] <= median_distance and np.mean(sorted(sim_matrix[i], reverse=True)[:5])>0.95\n",
    "# if np.mean(sorted(sim_matrix[i], reverse=True)[:3])>0.6 #if np.mean(sorted(sim_matrix[i][np.argsort(D[i])[:30]], reverse=True)[:5])>0.8\n",
    "selected_datasets = np.array(selected_datasets)\n",
    "print(len(selected_datasets))\n",
    "# mixed_X = mixed_X[selected_datasets]\n",
    "# mixed_Y = mixed_Y[selected_datasets]\n",
    "# mixed_Yn = mixed_Yn[selected_datasets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_pairs = [[j for j, yj in enumerate(y) if yj/max(y) >= 0.95] for y in Y[selected_datasets]]\n",
    "dist_matrix = D[selected_datasets][:, selected_datasets]\n",
    "nearest_neighbors = np.argsort(dist_matrix, axis=1)[:, :5]\n",
    "\n",
    "for i, neighbors in enumerate(nearest_neighbors):\n",
    "    reduced_neighbors = [j for j in neighbors if i in nearest_neighbors[j]]\n",
    "    print([len(set(good_pairs[i]).intersection(set(good_pairs[j]))) for j in reduced_neighbors])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(zip(*np.triu_indices(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "import pygad\n",
    "\n",
    "g = kneighbors_graph(X[selected_datasets], n_neighbors=5, metric=\"manhattan\").toarray()\n",
    "g = np.multiply(g, g.T)\n",
    "sumg = np.sum(g)\n",
    "\n",
    "def fitness_func(ga_instance, solution, solution_idx):\n",
    "    s = 0\n",
    "    for i, j in zip(*np.triu_indices(len(solution))):\n",
    "        s += 1 if g[i, j] > 0 and solution[i] != solution[j] else 0\n",
    "    s = 1 - s/sumg\n",
    "    # n = 1 - len(set(solution))/len(solution)\n",
    "    return s#(s + n)/ 2\n",
    "\n",
    "fitness_function = fitness_func\n",
    "\n",
    "num_generations = 1000\n",
    "num_parents_mating = 100\n",
    "\n",
    "sol_per_pop = 100\n",
    "num_genes = len(selected_datasets)\n",
    "gene_type = int\n",
    "\n",
    "gene_space = good_pairs\n",
    "\n",
    "parent_selection_type = \"sss\"\n",
    "keep_elitism = 1\n",
    "crossover_type = \"single_point\"\n",
    "crossover_probability = 0.8\n",
    "mutation_type = \"random\"\n",
    "mutation_probability = 0.2\n",
    "\n",
    "ga_instance = pygad.GA(num_generations=num_generations,\n",
    "                       num_parents_mating=num_parents_mating,\n",
    "                       fitness_func=fitness_function,\n",
    "                       sol_per_pop=sol_per_pop,\n",
    "                       num_genes=num_genes,\n",
    "                       gene_type=gene_type,\n",
    "                       gene_space=gene_space,\n",
    "                       parent_selection_type=parent_selection_type,\n",
    "                       keep_elitism=keep_elitism,\n",
    "                       crossover_type=crossover_type,\n",
    "                       crossover_probability=crossover_probability,\n",
    "                       mutation_type=mutation_type,\n",
    "                       mutation_probability=mutation_probability,\n",
    "                    #    parallel_processing=['process', 16],\n",
    "                    #    save_best_solutions=True\n",
    "                    )\n",
    "\n",
    "ga_instance.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ga_instance.plot_fitness()\n",
    "solution, solution_fitness, solution_idx = ga_instance.best_solution()\n",
    "s = 0\n",
    "n_pairs = len(solution)*(len(solution) - 1)/2\n",
    "for i, j in zip(*np.triu_indices(len(solution))):\n",
    "    s += 1 if g[i, j] > 0 and solution[i] != solution[j] else 0\n",
    "print(s/sumg)\n",
    "print(len(set(solution)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_pairs = benchmark_results[algorithm][\"original\"][eval_metric].columns\n",
    "print(set(similarity_pairs[solution]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE, MDS\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.stats import wasserstein_distance\n",
    "\n",
    "Xemb = TSNE(n_components=2, metric=\"manhattan\").fit_transform(X[selected_datasets])\n",
    "# Xemb = MDS(n_components=2, dissimilarity=\"precomputed\").fit_transform(pairwise_distances(X[selected_datasets], metric=\"manhattan\",n_jobs=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import TABLEAU_COLORS\n",
    "l = np.random.choice(list(TABLEAU_COLORS.values()), size=len(set(solution)))\n",
    "colors = dict(zip(set(solution), l))\n",
    "plt.figure(figsize=(4, 3))\n",
    "plt.scatter(\n",
    "    Xemb[:, 0], Xemb[:, 1],\n",
    "    s=30, c=[colors[v] for v in solution],\n",
    "    alpha=0.7\n",
    ")\n",
    "# plt.scatter(Xemb[bad, 0], Xemb[bad, 1], s=10, c=\"red\", alpha=0.7)\n",
    "plt.colorbar()\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from meta_model.ranking import ALL_MODELS\n",
    "from meta_model.ranking import scorer\n",
    "import pygad\n",
    "\n",
    "metrics = [\"euclidean\", \"manhattan\", \"cosine\"]\n",
    "weights = [\"uniform\", \"distance\"]\n",
    "def fitness_func(ga_instance, solution, solution_idx):\n",
    "    selected_features = np.array(solution[:X.shape[1]])>0\n",
    "    n_neighbors = solution[X.shape[1]]\n",
    "    metric = metrics[solution[X.shape[1]+1]]\n",
    "    w = weights[solution[X.shape[1]+2]]\n",
    "    knn = ALL_MODELS[\"KNN\"](n_neighbors=n_neighbors, metric=metric, weights=w)\n",
    "    fitness = np.mean(cross_val_score(knn, X[selected_datasets][:, selected_features], Y[selected_datasets], cv=5, scoring=scorer))\n",
    "    return fitness\n",
    "\n",
    "fitness_function = fitness_func\n",
    "\n",
    "num_generations = 200\n",
    "num_parents_mating = 100\n",
    "\n",
    "sol_per_pop = 100\n",
    "num_genes = X.shape[1] + 3\n",
    "gene_type = int\n",
    "\n",
    "init_range_low = [0 for _ in range(X.shape[1])] + [1, 0, 0]\n",
    "init_range_high = [1 for _ in range(X.shape[1])] + [20, 2, 1]\n",
    "gene_space = [[0, 1] for _ in range(X.shape[1])] + [range(1, 21), range(3), [0, 1]]\n",
    "\n",
    "parent_selection_type = \"sss\"\n",
    "keep_elitism = 1\n",
    "crossover_type = \"single_point\"\n",
    "crossover_probability = 0.85\n",
    "mutation_type = \"random\"\n",
    "mutation_probability = 0.1\n",
    "\n",
    "ga_instance = pygad.GA(num_generations=num_generations,\n",
    "                       num_parents_mating=num_parents_mating,\n",
    "                       fitness_func=fitness_function,\n",
    "                       sol_per_pop=sol_per_pop,\n",
    "                       num_genes=num_genes,\n",
    "                       gene_type=gene_type,\n",
    "                       init_range_low=init_range_low,\n",
    "                       init_range_high=init_range_high,\n",
    "                       gene_space=gene_space,\n",
    "                       parent_selection_type=parent_selection_type,\n",
    "                       keep_elitism=keep_elitism,\n",
    "                       crossover_type=crossover_type,\n",
    "                       crossover_probability=crossover_probability,\n",
    "                       mutation_type=mutation_type,\n",
    "                       mutation_probability=mutation_probability,\n",
    "                    #    parallel_processing=['process', 16],\n",
    "                    #    save_best_solutions=True\n",
    "                    )\n",
    "\n",
    "ga_instance.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ga_instance.plot_fitness()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # from sklearn.model_selection import cross_val_score\n",
    "# from meta_model.ranking import scorer\n",
    "# import pygad\n",
    "\n",
    "# max_features = [None, \"sqrt\", \"log2\"]\n",
    "# def fitness_func(ga_instance, solution, solution_idx):\n",
    "#     selected_features = np.array(solution[:X.shape[1]])>0\n",
    "#     min_samples_leaf = solution[X.shape[1]]\n",
    "#     max_depth = None if solution[X.shape[1]+1] < 2 else solution[X.shape[1]+1]\n",
    "#     m = max_features[solution[X.shape[1]+2]]\n",
    "#     dtree = ALL_MODELS[\"DTree\"](min_samples_leaf=min_samples_leaf, max_depth=max_depth, max_features=m)\n",
    "#     fitness = np.mean(cross_val_score(dtree, X[selected_datasets][:, selected_features], Y[selected_datasets], cv=5, scoring=scorer))\n",
    "#     return fitness\n",
    "\n",
    "# fitness_function = fitness_func\n",
    "\n",
    "# num_generations = 200\n",
    "# num_parents_mating = 50\n",
    "\n",
    "# sol_per_pop = 100\n",
    "# num_genes = X.shape[1] + 3\n",
    "# gene_type = int\n",
    "\n",
    "# init_range_low = [0 for _ in range(X.shape[1])] + [1, 0, 0]\n",
    "# init_range_high = [1 for _ in range(X.shape[1])] + [20, 10, 2]\n",
    "# gene_space = [[0, 1] for _ in range(X.shape[1])] + [range(1, 21), range(11), range(3)]\n",
    "\n",
    "# parent_selection_type = \"sss\"\n",
    "# keep_elitism = 1\n",
    "# crossover_type = \"single_point\"\n",
    "# crossover_probability = 0.85\n",
    "# mutation_type = \"random\"\n",
    "# mutation_probability = 0.1\n",
    "\n",
    "# ga_instance2 = pygad.GA(num_generations=num_generations,\n",
    "#                        num_parents_mating=num_parents_mating,\n",
    "#                        fitness_func=fitness_function,\n",
    "#                        sol_per_pop=sol_per_pop,\n",
    "#                        num_genes=num_genes,\n",
    "#                        gene_type=gene_type,\n",
    "#                        init_range_low=init_range_low,\n",
    "#                        init_range_high=init_range_high,\n",
    "#                        gene_space=gene_space,\n",
    "#                        parent_selection_type=parent_selection_type,\n",
    "#                        keep_elitism=keep_elitism,\n",
    "#                        crossover_type=crossover_type,\n",
    "#                        crossover_probability=crossover_probability,\n",
    "#                        mutation_type=mutation_type,\n",
    "#                        mutation_probability=mutation_probability,\n",
    "#                     #    parallel_processing=['process', 16],\n",
    "#                     #    save_best_solutions=True\n",
    "#                     )\n",
    "# ga_instance2.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def accept(y1, y2, t):\n",
    "#     if y2 <= y1:\n",
    "#         p = 1\n",
    "#     else:\n",
    "#         p = 0 if t==0 else np.exp((y1 - y2)/t)\n",
    "#     return np.random.random() <= p\n",
    "    \n",
    "# def heating(fitness, sample_generator, update, N=1000, alpha=1.1, c0=0.8):\n",
    "#     def f(t):\n",
    "#         x1 = sample_generator()\n",
    "#         x2 = update(x1)\n",
    "#         y1, y2 = fitness(x1), fitness(x2)\n",
    "#         return 1 if accept(y1, y2, t) else 0\n",
    "\n",
    "#     t = 0\n",
    "#     for _ in range(10):\n",
    "#         x1 = sample_generator()\n",
    "#         x2 = update(x1)\n",
    "#         t += abs(fitness(x2) - fitness(x1))/10\n",
    "        \n",
    "#     p_accept = 0\n",
    "#     while p_accept < c0:\n",
    "#         p_accept = 0\n",
    "#         for _ in range(N):\n",
    "#             p_accept += f(t)/N\n",
    "#         print(t, p_accept)\n",
    "#         t = alpha*t\n",
    "#     return t\n",
    "\n",
    "# def cooling(fitness, sample_generator, update, t0, N=1000, alpha=0.99, tf=1e-4, save_search=False):\n",
    "#     x1 = sample_generator()\n",
    "#     y1 = fitness(x1)\n",
    "#     best_x, best_y = x1, y1\n",
    "#     if save_search:\n",
    "#         search_history = {'temperature':[], 'best_y':[], 'y':[]}\n",
    "#     iter = 0\n",
    "#     n_iter_wt_improvement = 0\n",
    "#     t = t0\n",
    "#     while t > t0*tf and n_iter_wt_improvement < 20:\n",
    "#         imp = False\n",
    "#         if save_search:\n",
    "#             search_history['temperature'].append(t)\n",
    "#         for _ in range(N):\n",
    "#             x2 = update(x1)\n",
    "#             y2 = fitness(x2)\n",
    "#             if accept(y1, y2, t):\n",
    "#                 x1, y1 = x2, y2\n",
    "#             if y2 < best_y:\n",
    "#                 best_y = y2\n",
    "#                 best_x = x2\n",
    "#                 imp = True\n",
    "#                 n_iter_wt_improvement = 0\n",
    "        \n",
    "#         if save_search:\n",
    "#             search_history['best_y'].append(best_y)\n",
    "#             search_history['y'].append(y1)\n",
    "\n",
    "#         t = alpha*t\n",
    "#         iter += 1\n",
    "#         if not imp: \n",
    "#             n_iter_wt_improvement += 1\n",
    "#         print(\"iteration: {}, best_y: {:.3f}\".format(iter, best_y))\n",
    "#     if save_search:\n",
    "#         return best_x, best_y, search_history\n",
    "#     return best_x, best_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def select_features(X, Y, k=5):\n",
    "#     def fitness(x):\n",
    "#         s = 0\n",
    "#         D = pairwise_distances(X[:, x>0], n_jobs=-1)\n",
    "#         for i, dist_vec in enumerate(D):\n",
    "#             neighbors = [j for j in np.argsort(dist_vec) if j != i][:k]\n",
    "#             s += ndcg(Y[i], np.mean(Y[neighbors], axis=0))\n",
    "#             # s += np.mean(ndcg([Y[i]], Y[neighbors]))\n",
    "#         return -s/X.shape[0]\n",
    "#     # def fitness(x):\n",
    "#     #     knn = ALL_MODELS[\"KNN\"]()\n",
    "#     #     _, s = knn.cross_val_fit(X[:, x>0], Y, return_cv_scores=True)\n",
    "#     #     return -s\n",
    "\n",
    "#     def sample_generator():\n",
    "#         return np.random.randint(2, size=X.shape[1])\n",
    "\n",
    "#     def update(x):\n",
    "#         indices = np.random.choice(X.shape[1], size=1) #np.random.randint(5)\n",
    "#         new_x = np.array(x)\n",
    "#         new_x[indices] = 1 - new_x[indices]\n",
    "#         return new_x\n",
    "\n",
    "#     t0 = heating(fitness, sample_generator, update, N=500)\n",
    "#     # t0 = 0.0015\n",
    "#     print(\"t0: {}\".format(t0))\n",
    "#     best_x, best_y, search_history = cooling(fitness, sample_generator, update, t0, N=500, alpha=0.98, save_search=True)\n",
    "#     print(\"best_x: {} best_y: {:.3f}\".format(best_x, best_y))\n",
    "#     import matplotlib.pyplot as plt\n",
    "#     plt.plot(search_history[\"best_y\"])\n",
    "#     plt.show()\n",
    "#     return best_x, best_y\n",
    "# best_x, best_y = select_features(X, Yn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from meta_model.utils import ndcg\n",
    "from meta_model.ranking import ALL_MODELS\n",
    "from meta_model.ranking_tree import RankingTree\n",
    "from sklearn.model_selection import KFold, cross_val_predict\n",
    "\n",
    "models = {\n",
    "    \"KNN\": ALL_MODELS[\"KNN\"](),\n",
    "    # \"DTree\": ALL_MODELS[\"DTree\"](),\n",
    "    # \"KNN with FS\": ALL_MODELS[\"KNN\"](),\n",
    "    # \"DTree with FS\": ALL_MODELS[\"DTree\"](),\n",
    "}\n",
    "cv = KFold(n_splits=5)\n",
    "predictions = {model_name: np.zeros(shape=(len(selected_datasets), 120)) for model_name in models}\n",
    "predictions[\"AR\"] = np.zeros(shape=(len(selected_datasets), 120))\n",
    "i = 0\n",
    "\n",
    "models[\"KNN\"] = models[\"KNN\"].cross_val_fit(X[selected_datasets], Y[selected_datasets], n_splits=5) #\n",
    "predictions[\"KNN\"] = cross_val_predict(models[\"KNN\"], X[selected_datasets], Y[selected_datasets], cv=cv)\n",
    "# models[\"DTree\"] = models[\"DTree\"].cross_val_fit(X[selected_datasets], Y[selected_datasets], n_splits=5) #\n",
    "# predictions[\"DTree\"] = cross_val_predict(models[\"DTree\"], X[selected_datasets], Y[selected_datasets], cv=cv)\n",
    "\n",
    "# solution, solution_fitness, solution_idx = ga_instance.best_solution()\n",
    "# selected_features = np.array(solution[:X.shape[1]])>0\n",
    "# n_neighbors = solution[X.shape[1]]\n",
    "# metric = metrics[solution[X.shape[1]+1]]\n",
    "# w = weights[solution[X.shape[1]+2]]\n",
    "# knn = ALL_MODELS[\"KNN\"](n_neighbors=n_neighbors, metric=metric, weights=w)\n",
    "# predictions[\"KNN with FS\"] = cross_val_predict(knn, X[selected_datasets][:, selected_features], Y[selected_datasets], cv=cv)\n",
    "\n",
    "# solution, solution_fitness, solution_idx = ga_instance2.best_solution()\n",
    "# selected_features = np.array(solution[:X.shape[1]])>0\n",
    "# min_samples_leaf = solution[X.shape[1]]\n",
    "# max_depth = None if solution[X.shape[1]+1] < 2 else solution[X.shape[1]+1]\n",
    "# m = max_features[solution[X.shape[1]+2]]\n",
    "# dtree = ALL_MODELS[\"DTree\"](min_samples_leaf=min_samples_leaf, max_depth=max_depth, max_features=m)\n",
    "# predictions[\"DTree with FS\"] = cross_val_predict(dtree, X[selected_datasets][:, selected_features], Y[selected_datasets], cv=cv)\n",
    "\n",
    "for train, test in cv.split(X[selected_datasets]):\n",
    "    predictions[\"AR\"][test] = np.array([\n",
    "        [np.mean([v for v in Y[selected_datasets][train, j]]) for j in range(Y.shape[1])]\n",
    "        for _ in test\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(solution[:-3]>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_meta_df.columns[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_pair = np.argmax(mixed_Y[0]) #sim_pairs_index[\"manhattan_hamming\"]\n",
    "features = [i for i, v in enumerate(selected_features) if v]\n",
    "n_rows = len(features)\n",
    "n_cols = len(features)\n",
    "plt.figure(figsize=(2*n_cols, 2*n_rows))\n",
    "for i in range(n_rows - 1):\n",
    "    for j in range(i+1, n_cols):\n",
    "        plt.subplot(n_rows, n_cols, i*n_cols + j + 1)\n",
    "        plt.scatter(mixed_X[:,features[i]], mixed_X[:,features[j]], c=sim_matrix[0, :mixed_X.shape[0]], cmap=\"YlOrRd\", vmin=0., vmax=1)\n",
    "        # plt.scatter(mixed_X[:,features[i]], mixed_X[:,features[j]], c=sim_matrix[0, :mixed_X.shape[0]], cmap=\"YlOrRd\", vmin=0.5, vmax=1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "plt.tight_layout(h_pad=0, w_pad=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda:0\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "print(\"device:\", device)\n",
    "\n",
    "class View(nn.Module):\n",
    "    def __init__(self, shape):\n",
    "        super(View, self).__init__()\n",
    "        self.shape = shape\n",
    "    def forward(self, x):\n",
    "        return x.view(*self.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metric_learning import ContrastiveML\n",
    "import ranking\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "class MetaModel():\n",
    "    def __init__(self, mapping_function=None, ranking_model=\"KNN\", margin=1, device=\"cpu\"):\n",
    "        self.metric_learner = None if mapping_function is None else \\\n",
    "            ContrastiveML(mapping_function, margin)\n",
    "        self.ranker = ranking.ALL_MODELS[ranking_model]()\n",
    "        self.device = device\n",
    "\n",
    "    def _create_similarity_matrix(self, Y1, Y2=None):\n",
    "        return pairwise_distances(Y1, Y2, metric=lambda y1,y2: ndcg_sim(y1,y2,p=5), n_jobs=-1)\n",
    "        # return pairwise_distances(Y1, Y2)\n",
    "        # return pairwise_distances(Y1, Y2, metric=lambda y1, y2: custom_sim(y1, y2), n_jobs=-1)\n",
    "\n",
    "    def train_metric_learner(self, X_train, Y_train, metric_learning_params, X_test=None, Y_test=None):\n",
    "        if self.metric_learner is None:\n",
    "            return self\n",
    "        sim_matrix = self._create_similarity_matrix(Y_train)\n",
    "        X1, X2, y = [], [], []\n",
    "        for i in range(X_train.shape[0]-1):\n",
    "            for j in range(i+1, X_train.shape[0]):\n",
    "                X1.append(X_train[i])\n",
    "                X2.append(X_train[j])\n",
    "                similar = sim_matrix[i, j] > 0.95\n",
    "                y.append(0 if similar else 1)\n",
    "        X1, X2, y = np.array(X1), np.array(X2), np.array(y)\n",
    "        print()\n",
    "        print(\"classes distribution in train set:\", np.unique(y, return_counts=True))\n",
    "        train_dataset = torch.utils.data.TensorDataset(\n",
    "            torch.tensor(X1, device=self.device).float(),\n",
    "            torch.tensor(X2, device=self.device).float(),\n",
    "            torch.tensor(y, device=self.device).float()\n",
    "        )\n",
    "        test_dataset = None\n",
    "        if X_test is not None:\n",
    "            sim_matrix = self._create_similarity_matrix(Y_test, Y_train)\n",
    "            X1, X2, y = [], [], []\n",
    "            for i in range(X_test.shape[0]):\n",
    "                for j in range(X_train.shape[0]):\n",
    "                    X1.append(X_test[i])\n",
    "                    X2.append(X_train[j])\n",
    "                    similar = sim_matrix[i, j] > 0.95\n",
    "                    y.append(0 if similar else 1)\n",
    "            X1, X2, y = np.array(X1), np.array(X2), np.array(y)\n",
    "            print()\n",
    "            print(\"classes distribution in test set:\", np.unique(y, return_counts=True))\n",
    "            test_dataset = torch.utils.data.TensorDataset(\n",
    "                torch.tensor(X1, device=self.device).float(),\n",
    "                torch.tensor(X2, device=self.device).float(),\n",
    "                torch.tensor(y, device=self.device).float()\n",
    "            )\n",
    "        \n",
    "        self.metric_learner.to(self.device)\n",
    "        optimizer = torch.optim.Adam(self.metric_learner.parameters(), lr=metric_learning_params[\"lr\"])\n",
    "        metric_learning_params.pop(\"lr\")\n",
    "        self.metric_learner.fit(train_dataset, optimizer, test_dataset=test_dataset, **metric_learning_params)\n",
    "        return self\n",
    "\n",
    "    # def train_metric_learner(self, X_train, Y_train, metric_learning_params, X_test=None, Y_test=None):\n",
    "    #     if self.metric_learner is None:\n",
    "    #         return self\n",
    "    #     sim_matrix = self._create_similarity_matrix(Y_train)\n",
    "    #     d = pairwise_distances(X_train)\n",
    "    #     np.fill_diagonal(d, np.inf)\n",
    "    #     k = 30\n",
    "    #     nearest_neighbors = np.argsort(d, axis=1)[:, :k]\n",
    "    #     X1, X2, y = [], [], []\n",
    "    #     for i in range(X_train.shape[0]):\n",
    "    #         l = [j for j in np.argsort(-sim_matrix[i]) if j in nearest_neighbors[i]][:5]\n",
    "    #         for j in nearest_neighbors[i]:\n",
    "    #             if j in l:\n",
    "    #                 X1.append(X_train[i])\n",
    "    #                 X2.append(X_train[j])\n",
    "    #                 y.append(0)\n",
    "    #             elif sim_matrix[i, j] < 0.95:\n",
    "    #                 X1.append(X_train[i])\n",
    "    #                 X2.append(X_train[j])\n",
    "    #                 y.append(1)\n",
    "\n",
    "    #     X1, X2, y = np.array(X1), np.array(X2), np.array(y)\n",
    "    #     print()\n",
    "    #     print(\"classes distribution in train set:\", np.unique(y, return_counts=True))\n",
    "    #     train_dataset = torch.utils.data.TensorDataset(\n",
    "    #         torch.tensor(X1, device=self.device).float(),\n",
    "    #         torch.tensor(X2, device=self.device).float(),\n",
    "    #         torch.tensor(y, device=self.device).float()\n",
    "    #     )\n",
    "    #     test_dataset = None\n",
    "    #     if X_test is not None:\n",
    "    #         sim_matrix = self._create_similarity_matrix(Y_test, Y_train)\n",
    "    #         d = pairwise_distances(X_test, X_train)\n",
    "    #         nearest_neighbors = np.argsort(d, axis=1)[:, :k]\n",
    "    #         X1, X2, y = [], [], []\n",
    "    #         for i in range(X_test.shape[0]):\n",
    "    #             l = [j for j in np.argsort(-sim_matrix[i]) if j in nearest_neighbors[i]][:5]\n",
    "    #             for j in nearest_neighbors[i]:\n",
    "    #                 if j in l:\n",
    "    #                     X1.append(X_test[i])\n",
    "    #                     X2.append(X_train[j])\n",
    "    #                     y.append(0)\n",
    "    #                 elif sim_matrix[i, j] < 0.95:\n",
    "    #                     X1.append(X_test[i])\n",
    "    #                     X2.append(X_train[j])\n",
    "    #                     y.append(1)\n",
    "    #         X1, X2, y = np.array(X1), np.array(X2), np.array(y)\n",
    "    #         print()\n",
    "    #         print(\"classes distribution in test set:\", np.unique(y, return_counts=True))\n",
    "    #         test_dataset = torch.utils.data.TensorDataset(\n",
    "    #             torch.tensor(X1, device=self.device).float(),\n",
    "    #             torch.tensor(X2, device=self.device).float(),\n",
    "    #             torch.tensor(y, device=self.device).float()\n",
    "    #         )\n",
    "        \n",
    "    #     self.metric_learner.to(self.device)\n",
    "    #     optimizer = torch.optim.Adam(self.metric_learner.parameters(), lr=metric_learning_params[\"lr\"])\n",
    "    #     metric_learning_params.pop(\"lr\")\n",
    "    #     self.metric_learner.fit(train_dataset, optimizer, test_dataset=test_dataset, **metric_learning_params)\n",
    "    #     return self\n",
    "\n",
    "    # def train_metric_learner(self, X_train, Y_train, metric_learning_params, X_val=None, Y_val=None):\n",
    "    #     if self.metric_learner is None:\n",
    "    #         return self\n",
    "    #     k = 3\n",
    "    #     sim_matrix = self._create_similarity_matrix(Y_train)\n",
    "    #     np.fill_diagonal(sim_matrix, 0)\n",
    "    #     nearest_neighbors = np.argsort(-sim_matrix, axis=1)[:, :k]\n",
    "    #     X1, X2, y = [], [], []\n",
    "    #     for i in range(X_train.shape[0]):\n",
    "    #         for j in nearest_neighbors[i]:\n",
    "    #             X1.append(X_train[i])\n",
    "    #             X2.append(X_train[j])\n",
    "    #             y.append(0)\n",
    "    #     for i in range(X_train.shape[0]-1):\n",
    "    #         for j in range(i, X_train.shape[0]):\n",
    "    #             if i not in nearest_neighbors[j] and j not in nearest_neighbors[i]:\n",
    "    #                 X1.append(X_train[i])\n",
    "    #                 X2.append(X_train[j])\n",
    "    #                 y.append(1)\n",
    "    #     X1, X2, y = np.array(X1), np.array(X2), np.array(y)\n",
    "    #     print(\"classes distribution in train set:\", np.unique(y, return_counts=True))\n",
    "    #     train_set = torch.utils.data.TensorDataset(\n",
    "    #         torch.tensor(X1, device=self.device).float(),\n",
    "    #         torch.tensor(X2, device=self.device).float(),\n",
    "    #         torch.tensor(y, device=self.device).float()\n",
    "    #     )\n",
    "    #     train_loader = torch.utils.data.DataLoader(train_set, batch_size=metric_learning_params[\"batch_size_train\"])\n",
    "\n",
    "    #     val_loader = None\n",
    "    #     if X_val is not None:\n",
    "    #         sim_matrix = self._create_similarity_matrix(Y_val, Y_train)\n",
    "    #         nearest_neighbors = np.argsort(-sim_matrix, axis=1)[:, :k]\n",
    "    #         X1, X2, y = [], [], []\n",
    "    #         for i in range(X_val.shape[0]):\n",
    "    #             for j in range(X_train.shape[0]):\n",
    "    #                 X1.append(X_val[i])\n",
    "    #                 X2.append(X_train[j])\n",
    "    #                 y.append(0 if j in nearest_neighbors[i] else 1)\n",
    "    #         X1, X2, y = np.array(X1), np.array(X2), np.array(y)\n",
    "    #         print(\"classes distribution in train set:\", np.unique(y, return_counts=True))\n",
    "    #         val_set = torch.utils.data.TensorDataset(\n",
    "    #             torch.tensor(X1, device=device).float(),\n",
    "    #             torch.tensor(X2, device=device).float(),\n",
    "    #             torch.tensor(y, device=device).float()\n",
    "    #         )\n",
    "    #         val_loader = torch.utils.data.DataLoader(val_set, batch_size=metric_learning_params[\"batch_size_val\"])\n",
    "                    \n",
    "    #     self.metric_learner.to(self.device)\n",
    "    #     optimizer = torch.optim.Adam(\n",
    "    #         self.metric_learner.parameters(),\n",
    "    #         lr=metric_learning_params[\"lr\"],\n",
    "    #         weight_decay=metric_learning_params[\"weight_decay\"]\n",
    "    #     )\n",
    "    #     self.metric_learner.fit(\n",
    "    #         train_loader, optimizer, \n",
    "    #         val_loader=val_loader,\n",
    "    #         epochs=metric_learning_params[\"epochs\"]\n",
    "    #     )\n",
    "\n",
    "    def embbed(self, X):\n",
    "        if self.metric_learner is None:\n",
    "            return X\n",
    "        with torch.no_grad():\n",
    "            Z = self.metric_learner(torch.tensor(X, device=self.device).float()).cpu().detach().numpy()\n",
    "        return Z\n",
    "\n",
    "    def train_ranker(self, Ztrain, Y_train):\n",
    "        self.ranker = self.ranker.cross_val_fit(Ztrain, Y_train)\n",
    "        return self\n",
    "\n",
    "\n",
    "    def fit(self, X_train, Y_train, metric_learning_params, X_test=None, Y_test=None):\n",
    "        self.train_metric_learner(X_train, Y_train, metric_learning_params, X_test=X_test, Y_test=Y_test)\n",
    "        Ztrain = self.embbed(X_train)\n",
    "        self.train_ranker(Ztrain, Y_train)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.ranker.predict(self.embbed(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metric_learning import AE\n",
    "import ranking\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "class MetaModel2():\n",
    "    def __init__(self, encoder=None, decoder=None, ranking_model=\"KNN\", device=\"cpu\"):\n",
    "        self.metric_learner = None if encoder is None else \\\n",
    "            AE(encoder, decoder)\n",
    "        self.ranker = ranking.ALL_MODELS[ranking_model]()\n",
    "        self.device = device\n",
    "\n",
    "    def train_metric_learner(self, X_train, metric_learning_params, X_val=None):\n",
    "        train_set = torch.utils.data.TensorDataset(torch.tensor(X_train, device=self.device).float())\n",
    "        train_loader = torch.utils.data.DataLoader(train_set, batch_size=metric_learning_params[\"batch_size_train\"])\n",
    "        \n",
    "        val_loader = None\n",
    "        if X_val is not None:\n",
    "            val_set = torch.utils.data.TensorDataset(torch.tensor(X_val, device=self.device).float())\n",
    "            val_loader = torch.utils.data.DataLoader(val_set, batch_size=metric_learning_params[\"batch_size_val\"])\n",
    "        \n",
    "        self.metric_learner.to(self.device)\n",
    "        optimizer = torch.optim.Adam(\n",
    "            self.metric_learner.parameters(),\n",
    "            lr=metric_learning_params[\"lr\"],\n",
    "            weight_decay=metric_learning_params[\"weight_decay\"]\n",
    "        )\n",
    "        self.metric_learner.fit(\n",
    "            train_loader, optimizer,\n",
    "            val_loader=val_loader,\n",
    "            epochs=metric_learning_params[\"epochs\"]\n",
    "        )\n",
    "        return self\n",
    "\n",
    "    def embbed(self, X):\n",
    "        if self.metric_learner is None:\n",
    "            return X\n",
    "        with torch.no_grad():\n",
    "            Z = self.metric_learner(torch.tensor(X, device=self.device).float()).cpu().detach().numpy()\n",
    "        return Z\n",
    "\n",
    "    def train_ranker(self, Ztrain, Y_train):\n",
    "        self.ranker = self.ranker.cross_val_fit(Ztrain, Y_train)\n",
    "        return self\n",
    "\n",
    "\n",
    "    def fit(self, X_train, Y_train, metric_learning_params, X_test=None, Y_test=None):\n",
    "        self.train_metric_learner(X_train, Y_train, metric_learning_params, X_test=X_test, Y_test=Y_test)\n",
    "        Ztrain = self.embbed(X_train)\n",
    "        self.train_ranker(Ztrain, Y_train)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.ranker.predict(self.embbed(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE, MDS\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.stats import wasserstein_distance\n",
    "\n",
    "# Xemb = TSNE(n_components=2, metric=\"manhattan\").fit_transform(X)\n",
    "Xemb = MDS(n_components=2, dissimilarity=\"precomputed\").fit_transform(pairwise_distances(X, metric=\"manhattan\",n_jobs=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input = torch.randn(20, 300)\n",
    "# m = nn.Sequential(\n",
    "#     View((-1, 1, 300)),\n",
    "#     nn.Conv1d(1, 64, 3, stride=3, padding=0), #100\n",
    "#     nn.ReLU(),\n",
    "#     nn.Conv1d(64, 128, 2, stride=2, padding=0), #50\n",
    "#     nn.ReLU(),\n",
    "#     nn.Conv1d(128, 256, 5, stride=5, padding=0), #10\n",
    "#     # nn.ReLU(),\n",
    "#     # nn.Flatten(),\n",
    "#     # nn.Linear(512*10, 1024),\n",
    "#     # nn.ReLU(),\n",
    "#     # nn.Linear(1024, 32),\n",
    "#     # nn.ReLU(),\n",
    "#     # nn.Linear(256, 32)\n",
    "# )\n",
    "\n",
    "# m(input).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_pair = np.argmax(mixed_Y[10]) #sim_pairs_index[\"manhattan_hamming\"]\n",
    "print(sim_pair)\n",
    "indices = [i for i, y in enumerate(mixed_Y) if y[sim_pair] > 0]\n",
    "print(len(indices))\n",
    "plt.figure(figsize=(4, 3))\n",
    "plt.scatter(\n",
    "    Xemb[indices, 0], Xemb[indices, 1],\n",
    "    s=30, c=Y[indices, sim_pair],\n",
    "    edgecolors=[\"black\" if i < mixed_X.shape[0] else \"none\" for i in indices],\n",
    "    linewidth=[1 if i < mixed_X.shape[0] else 0 for i in indices],\n",
    "    alpha=0.7, vmin=0, vmax=1)\n",
    "# plt.scatter(Xemb[bad, 0], Xemb[bad, 1], s=10, c=\"red\", alpha=0.7)\n",
    "plt.colorbar()\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = selected_datasets[0]\n",
    "plt.figure(figsize=(4, 3))\n",
    "plt.scatter(\n",
    "    Xemb[:, 0], Xemb[:, 1], c=Y[:, 0], s=30, alpha=1, \n",
    "    edgecolors=['none' if k!=i else \"red\" for k in range(Xemb.shape[0])],\n",
    "    linewidth=[0 if k!=i else 2 for k in range(Xemb.shape[0])],\n",
    "    vmin=0, vmax=1\n",
    ")\n",
    "plt.colorbar()\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1234)\n",
    "test_index = np.random.choice(selected_datasets, size=3, replace=False)\n",
    "# test_index = selected_datasets\n",
    "train_index = [i for i in range(mixed_X.shape[0]) if i not in test_index]\n",
    "X_train, X_test = X[train_index], X[test_index]\n",
    "Y_trainr, Y_testr = Y[train_index], Y[test_index]\n",
    "Y_trainn, Y_testn = Yn[train_index], Yn[test_index]\n",
    "embeddings = [Xemb]\n",
    "network = nn.Sequential(\n",
    "    nn.Linear(X_train.shape[1], 32),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(32, 16),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(16, 8),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(8, 2),\n",
    ")\n",
    "\n",
    "# network = nn.Sequential(\n",
    "#     View((-1, 1, X_train.shape[1])),\n",
    "#     nn.Conv1d(1, 8, 5, stride=1, padding=\"same\"), #300\n",
    "#     nn.ReLU(),\n",
    "#     nn.Conv1d(8, 8, 3, stride=3, padding=0), #100\n",
    "#     nn.ReLU(),\n",
    "#     nn.Conv1d(8, 16, 3, stride=1, padding=\"same\"), #100\n",
    "#     nn.ReLU(),\n",
    "#     nn.Conv1d(16, 16, 2, stride=2, padding=0), #50\n",
    "#     nn.ReLU(),\n",
    "#     nn.Conv1d(16, 32, 3, stride=1, padding=0), #48\n",
    "#     nn.ReLU(),\n",
    "#     nn.Conv1d(32, 64, 4, stride=4, padding=0), #12\n",
    "#     nn.ReLU(),\n",
    "#     nn.Conv1d(64, 128, 3, stride=3, padding=0), #4\n",
    "#     nn.ReLU(),\n",
    "#     nn.Flatten(),\n",
    "#     nn.Linear(128*4, 32)\n",
    "#     # nn.ReLU(),\n",
    "#     # nn.Linear(256, 32)\n",
    "# )\n",
    "# network.to(device)\n",
    "model = MetaModel(network, margin=1, device=device)\n",
    "# network = nn.Sequential(\n",
    "#     nn.Linear(X_train.shape[1], 64),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Linear(64, 32),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Linear(32, 16),\n",
    "#     # nn.ReLU(),\n",
    "#     # nn.Linear(16, 8)\n",
    "# )\n",
    "# network.to(device)\n",
    "# decoder = nn.Sequential(\n",
    "#     # nn.Linear(8, 16),\n",
    "#     # nn.ReLU(),\n",
    "#     nn.Linear(16, 32),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Linear(32, 64),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Linear(64, X_train.shape[1])\n",
    "# )\n",
    "# decoder.to(device)\n",
    "# model = MetaModel2(network, decoder, device=device)\n",
    "\n",
    "for i in range(1):\n",
    "    # metric_learning_params = {\n",
    "    #     \"lr\": 1e-3,\n",
    "    #     \"weight_decay\": 1e-5,\n",
    "    #     \"epochs\": 200,\n",
    "    #     \"batch_size_train\": 16,\n",
    "    #     \"batch_size_val\": 16,\n",
    "    # }\n",
    "    # # new_X_train = []\n",
    "    # # for x in X_train:\n",
    "    # #     for _ in range(100):\n",
    "    # #         new_X_train.append(np.random.normal(x, 0.01))\n",
    "    # # new_X_train = np.array(new_X_train)\n",
    "    # model.train_metric_learner(\n",
    "    #     X_train,\n",
    "    #     metric_learning_params,\n",
    "    #     X_val=X_test\n",
    "    # )\n",
    "    # plt.figure(figsize=(3, 2))\n",
    "    # plt.plot(model.metric_learner.history[\"train\"][\"loss\"], label=\"train loss\")\n",
    "    # plt.plot(model.metric_learner.history[\"val\"][\"loss\"], \"--\", label=\"val loss\")\n",
    "    # plt.legend()\n",
    "    # plt.show()\n",
    "\n",
    "    metric_learning_params = {\n",
    "        \"lr\": 1e-3,\n",
    "        \"weight_decay\": 1e-5,\n",
    "        \"epochs\": 150,\n",
    "        \"batch_size_train\": 32,\n",
    "        \"batch_size_val\": 32,\n",
    "    }\n",
    "    j = 67\n",
    "    model.train_metric_learner(\n",
    "        X_train, Y_trainn,\n",
    "        metric_learning_params,\n",
    "        X_val=X_test, Y_val=Y_testn\n",
    "    )\n",
    "    plt.figure(figsize=(3, 2))\n",
    "    plt.plot(model.metric_learner.history[\"train\"][\"loss\"], label=\"train loss\")\n",
    "    plt.plot(model.metric_learner.history[\"val\"][\"loss\"], \"--\", label=\"val loss\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    embeddings.append(model.embbed(mixed_X))\n",
    "    # embeddings.append(TSNE(n_components=2).fit_transform(model.embbed(mixed_X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows, cols = len(test_index), len(embeddings)\n",
    "plt.figure(figsize=(cols*3, rows*2))\n",
    "for i, ind in enumerate(test_index):\n",
    "    for j, Z in enumerate(embeddings):\n",
    "        plt.subplot(rows, cols, i*cols + j + 1)\n",
    "        plt.scatter(\n",
    "            Z[:, 0], Z[:, 1], c=sim_matrix[ind][:mixed_X.shape[0]], s=40, alpha=0.7, \n",
    "            edgecolors=['none' if k!=ind else \"red\" for k in range(Z.shape[0])],\n",
    "            linewidth=[0 if  k!=ind else 1 for k in range(Z.shape[0])],\n",
    "            vmin=0., vmax=1)\n",
    "        # plt.colorbar()\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "plt.tight_layout(w_pad=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "ranking_model_names = [\"KNN\", \"RF\"] #, \"KNN with aug.\", \"RF with aug.\"\n",
    "for name in ranking_model_names:\n",
    "    predictions[f\"AE+{name}\"] = np.zeros(shape=Y[selected_datasets].shape)\n",
    "\n",
    "i = 0\n",
    "for train, test in KFold(n_splits=10, shuffle=True, random_state=0).split(X[selected_datasets]):\n",
    "    print(i, \"---------------------------------------\")\n",
    "    test_index = selected_datasets[test]\n",
    "\n",
    "    train_index = [i for i in range(mixed_X.shape[0]) if i not in test_index]\n",
    "    train_index_aug = [i for i in range(X.shape[0]) if i not in test_index]\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    Y_trainr, Y_testr = Y[train_index], Y[test_index]\n",
    "    Y_trainn, Y_testn = Yn[train_index], Yn[test_index]\n",
    "    X_train_aug = X[train_index_aug]\n",
    "    Y_trainr_aug = Y[train_index_aug]\n",
    "    Y_trainn_aug = Yn[train_index_aug]\n",
    "\n",
    "    network = nn.Sequential(\n",
    "        nn.Linear(X_train.shape[1], 16),\n",
    "        # nn.ReLU(),\n",
    "        # nn.Linear(16, 8),\n",
    "        # nn.ReLU(),\n",
    "        # nn.Linear(8, 4)\n",
    "    )\n",
    "    network.to(device)\n",
    "    decoder = nn.Sequential(\n",
    "        # nn.Linear(4, 8),\n",
    "        # nn.ReLU(),\n",
    "        # nn.Linear(8, 16),\n",
    "        # nn.ReLU(),\n",
    "        nn.Linear(16, X_train.shape[1])\n",
    "    )\n",
    "    decoder.to(device)\n",
    "    model = MetaModel2(network, decoder, device=device)\n",
    "    metric_learning_params = {\n",
    "        \"lr\": 1e-3,\n",
    "        \"weight_decay\": 0,\n",
    "        \"epochs\": 400,\n",
    "        \"batch_size_train\": 16,\n",
    "        \"batch_size_val\": 16,\n",
    "    }\n",
    "    model.train_metric_learner(\n",
    "        X_train,\n",
    "        metric_learning_params,\n",
    "        X_val=X_test\n",
    "    )\n",
    "\n",
    "    # plt.figure(figsize=(4, 2.5))\n",
    "    # plt.plot(model.metric_learner.history[\"train\"][\"loss\"], label=\"train loss\")\n",
    "    # plt.plot(model.metric_learner.history[\"val\"][\"loss\"], \"--\", label=\"val loss\")\n",
    "    # plt.legend()\n",
    "    # plt.show()\n",
    "\n",
    "    Z_train = model.embbed(X_train)\n",
    "    for name in [\"KNN\", \"RF\"]:\n",
    "        model.ranker = ALL_MODELS[name]()\n",
    "        model.train_ranker(Z_train, Y_trainr)\n",
    "        predictions[f\"AE+{name}\"][test] = model.predict(X_test)\n",
    "\n",
    "    # network = nn.Sequential(\n",
    "    #     nn.Linear(X_train.shape[1], 64),\n",
    "    #     nn.ReLU(),\n",
    "    #     nn.Linear(64, 32),\n",
    "    #     nn.ReLU(),\n",
    "    #     nn.Linear(32, 16),\n",
    "    #     # nn.ReLU(),\n",
    "    #     # nn.Linear(16, 8),\n",
    "    #     # nn.ReLU(),\n",
    "    #     # nn.Linear(8, 4)\n",
    "    # )\n",
    "    # network.to(device)\n",
    "    # decoder = nn.Sequential(\n",
    "    #     # nn.Linear(4, 8),\n",
    "    #     # nn.ReLU(),\n",
    "    #     # nn.Linear(8, 16),\n",
    "    #     # nn.ReLU(),\n",
    "    #     nn.Linear(16, 32),\n",
    "    #     nn.ReLU(),\n",
    "    #     nn.Linear(32, 64),\n",
    "    #     nn.ReLU(),\n",
    "    #     nn.Linear(64, X_train.shape[1])\n",
    "    # )\n",
    "    # decoder.to(device)\n",
    "    # model = MetaModel2(network, decoder, device=device)\n",
    "    # metric_learning_params = {\n",
    "    #     \"lr\": 1e-3,\n",
    "    #     \"weight_decay\": 1e-4,\n",
    "    #     \"epochs\": 250,\n",
    "    #     \"batch_size_train\": 16,\n",
    "    #     \"batch_size_val\": 16,\n",
    "    # }\n",
    "    # model.train_metric_learner(\n",
    "    #     X_train_aug,\n",
    "    #     metric_learning_params,\n",
    "    #     X_val=X_test\n",
    "    # )\n",
    "\n",
    "    # # plt.figure(figsize=(4, 2.5))\n",
    "    # # plt.plot(model.metric_learner.history[\"train\"][\"loss\"], label=\"train loss\")\n",
    "    # # plt.plot(model.metric_learner.history[\"val\"][\"loss\"], \"--\", label=\"val loss\")\n",
    "    # # plt.legend()\n",
    "    # # plt.show()\n",
    "\n",
    "    # Z_train_aug = model.embbed(X_train_aug)\n",
    "    # for name in [\"KNN with aug.\", \"RF with aug.\"]:\n",
    "    #     model.ranker = ALL_MODELS[name.split(\" \")[0]]()\n",
    "    #     model.train_ranker(Z_train_aug, Y_trainr_aug)\n",
    "    #     predictions[f\"AE+{name}\"][test] = model.predict(X_test)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import KFold\n",
    "# ranking_model_names = [\"KNN\", \"RF\"] # , \"KNN with aug.\", \"RF with aug.\"\n",
    "# for name in ranking_model_names:\n",
    "#     predictions[f\"Mtrl+{name}\"] = np.zeros(shape=Y[selected_datasets].shape)\n",
    "\n",
    "# i = 0\n",
    "# for train, test in cv.split(X[selected_datasets]):\n",
    "#     print(i, \"---------------------------------------\")\n",
    "#     test_index = selected_datasets[test]\n",
    "\n",
    "#     train_index = [i for i in range(mixed_X.shape[0]) if i not in test_index]\n",
    "#     train_index_aug = [i for i in range(X.shape[0]) if i not in test_index]\n",
    "#     X_train, X_test = X[train_index][:, selected_features], X[test_index][:, selected_features]\n",
    "#     Y_trainr, Y_testr = Y[train_index], Y[test_index]\n",
    "#     Y_trainn, Y_testn = Yn[train_index], Yn[test_index]\n",
    "#     X_train_aug = X[train_index_aug]\n",
    "#     Y_trainr_aug = Y[train_index_aug]\n",
    "#     Y_trainn_aug = Yn[train_index_aug]\n",
    "\n",
    "#     network = nn.Sequential(\n",
    "#         nn.Linear(X_train.shape[1], 16),\n",
    "#         # nn.ReLU(),\n",
    "#         # nn.Linear(128, 64),\n",
    "#         # nn.ReLU(),\n",
    "#         # nn.ReLU(),\n",
    "#         # nn.Linear(16, 8),\n",
    "#         # nn.ReLU(),\n",
    "#         # nn.Linear(8, 4),\n",
    "#     )\n",
    "#     network.to(device)\n",
    "#     model = MetaModel(network, margin=2, device=device)\n",
    "#     metric_learning_params = {\n",
    "#         \"lr\": 1e-3,\n",
    "#         \"weight_decay\": 0,\n",
    "#         \"epochs\": 400,\n",
    "#         \"batch_size_train\": 16,\n",
    "#         \"batch_size_val\": 16,\n",
    "#     }\n",
    "#     model.train_metric_learner(\n",
    "#         X_train, Y_trainn,\n",
    "#         metric_learning_params,\n",
    "#         X_val=X_test, Y_val=Y_testn\n",
    "#     )\n",
    "\n",
    "#     # plt.figure(figsize=(4, 2.5))\n",
    "#     # plt.plot(model.metric_learner.history[\"train\"][\"loss\"], label=\"train loss\")\n",
    "#     # plt.plot(model.metric_learner.history[\"val\"][\"loss\"], \"--\", label=\"val loss\")\n",
    "#     # plt.legend()\n",
    "#     # plt.show()\n",
    "\n",
    "#     Z_train = model.embbed(X_train)\n",
    "#     for name in [\"KNN\", \"RF\"]:\n",
    "#         model.ranker = ALL_MODELS[name]()\n",
    "#         model.train_ranker(Z_train, Y_trainn)\n",
    "#         predictions[f\"Mtrl+{name}\"][test] = model.predict(X_test)\n",
    "\n",
    "#     ##################################################\n",
    "#     # network = nn.Sequential(\n",
    "#     #     nn.Linear(X_train.shape[1], 64),\n",
    "#     #     nn.ReLU(),\n",
    "#     #     nn.Linear(64, 32),\n",
    "#     #     nn.ReLU(),\n",
    "#     #     nn.Linear(32, 24),\n",
    "#     #     # nn.ReLU(),\n",
    "#     #     # nn.Linear(16, 8),\n",
    "#     #     # nn.ReLU(),\n",
    "#     #     # nn.Linear(8, 4),\n",
    "#     # )\n",
    "#     # network.to(device)\n",
    "#     # model = MetaModel(network, margin=1, device=device)\n",
    "#     # metric_learning_params = {\n",
    "#     #     \"lr\": 1e-3,\n",
    "#     #     \"weight_decay\": 1e-4,\n",
    "#     #     \"epochs\": 100,\n",
    "#     #     \"batch_size_train\": 256,\n",
    "#     #     \"batch_size_val\": 256,\n",
    "#     # }\n",
    "#     # model.train_metric_learner(\n",
    "#     #     X_train_aug, Y_trainn_aug,\n",
    "#     #     metric_learning_params,\n",
    "#     #     X_val=X_test, Y_val=Y_testn\n",
    "#     # )\n",
    "\n",
    "#     # # plt.figure(figsize=(4, 2.5))\n",
    "#     # # plt.plot(model.metric_learner.history[\"train\"][\"loss\"], label=\"train loss\")\n",
    "#     # # plt.plot(model.metric_learner.history[\"val\"][\"loss\"], \"--\", label=\"val loss\")\n",
    "#     # # plt.legend()\n",
    "#     # # plt.show()\n",
    "\n",
    "#     # Z_train_aug = model.embbed(X_train_aug)\n",
    "#     # for name in [\"KNN with aug.\", \"RF with aug.\"]:\n",
    "#     #     model.ranker = ALL_MODELS[name.split(\" \")[0]]()\n",
    "#     #     model.train_ranker(Z_train_aug, Y_trainn_aug)\n",
    "#     #     predictions[f\"Mtrl+{name}\"][test] = model.predict(X_test)\n",
    "#     i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_pairs = {\n",
    "    \"haverage\": \"manhattan_hamming\",\n",
    "    \"fasterpam\": \"euclidean_hamming\",\n",
    "    \"kprototypes\": \"sqeuclidean_hamming\",\n",
    "}\n",
    "similarity_pairs = benchmark_results[algorithm][\"original\"][eval_metric].columns\n",
    "sim_pairs_index = dict(zip(similarity_pairs, range(len(similarity_pairs))))\n",
    "\n",
    "ndcg_ranks = [1, 3, 5, 10, 15, 20]\n",
    "n_bests = [1, 3, 5, 10]\n",
    "ndcg_scores = {\n",
    "    model_name: {p: np.zeros(len(selected_datasets)) for p in ndcg_ranks}\n",
    "    for model_name in predictions\n",
    "} #| {'ensemble': {p: np.zeros(meta_X.shape[0]) for p in ndcg_ranks}}\n",
    "\n",
    "lb_scores = np.zeros(len(selected_datasets))\n",
    "rb_scores = {k: np.zeros(len(selected_datasets)) for k in n_bests}\n",
    "mb_scores = np.zeros(len(selected_datasets))\n",
    "model_scores = {\n",
    "    model_name: {k: np.zeros(len(selected_datasets)) for k in n_bests}\n",
    "    for model_name in predictions\n",
    "} #| {'ensemble': {k: np.zeros(len(test_index)) for k in n_bests}}\n",
    "\n",
    "for name, Y_pred in predictions.items():\n",
    "    Y_pred = np.array(Y_pred)\n",
    "    for p in ndcg_ranks:\n",
    "        ndcg_scores[name][p] = ndcg(Y[selected_datasets], Y_pred, p=p)\n",
    "\n",
    "for name, Y_pred in predictions.items():\n",
    "    Y_pred = np.array(Y_pred)\n",
    "    for k in n_bests:\n",
    "        model_scores[name][k] = np.array(\n",
    "            [max(y[y > 0][np.argsort(-Y_pred[i][y > 0])[:k]]) for i, y in enumerate(Y[selected_datasets])])\n",
    "\n",
    "for k in n_bests:\n",
    "    rb_scores[k] = np.array(\n",
    "        [max(np.random.choice(y[y > 0], k)) for y in Y[selected_datasets]])\n",
    "\n",
    "lb_scores = Y[selected_datasets][:, sim_pairs_index[baseline_pairs[algorithm]]]\n",
    "mb_scores = np.array([max(y) for y in Y[selected_datasets]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "list_indices = [\n",
    "    [i for i, y in enumerate(Y[selected_datasets]) if np.mean(1 - y[y>0]/max(y[y>0])) < 0.0], #test_index[i] in base_datasets and # i in test and\n",
    "    [i for i, y in enumerate(Y[selected_datasets]) if np.mean(1 - y[y>0]/max(y[y>0])) >= 0.]\n",
    "]\n",
    "rows, cols = 1, len(list_indices)\n",
    "plt.figure(figsize=(cols*4, rows*3))\n",
    "subplot_num = 1\n",
    "exclude = [] #\"KNN with aug.\", \"RF with aug.\" - \"KNN\", \"RF\", \"AE+KNN\", \"AE+RF\"\n",
    "for indices in list_indices:\n",
    "    scores = {k:v for k, v in model_scores.items() if k not in exclude} \n",
    "    # scores[\"RB\"] = rb_scores\n",
    "    scores[\"LB\"] = lb_scores\n",
    "    scores[\"Best\"] = mb_scores\n",
    "\n",
    "    y = {key: [] for key in scores}\n",
    "\n",
    "    for name, score in scores.items():\n",
    "        for k in n_bests:\n",
    "            u = score[indices] if name in [\"LB\", \"Best\"] else score[k][indices]\n",
    "            y[name].append(np.mean(u))\n",
    "\n",
    "    plt.subplot(rows, cols, subplot_num)\n",
    "    for name, values in y.items():\n",
    "        plt.plot(n_bests, values, label=name)\n",
    "    plt.ylabel(\"Mean accuracy\")\n",
    "    plt.xlabel(\"Number of recommended pair\")\n",
    "    # plt.ylim((0.67, 0.9))\n",
    "    plt.legend(fontsize=8, loc= \"upper left\", bbox_to_anchor= (1, 1))\n",
    "    plt.grid(axis=\"y\")\n",
    "    plt.title(len(indices))\n",
    "    subplot_num += 1\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"output/mean_acc2.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "indices = [i for i, y in enumerate(Y[selected_datasets]) if np.mean(1 - y[y>0]/max(y[y>0])) >= 0]\n",
    "\n",
    "exclude = []\n",
    "scores = {k:v for k, v in model_scores.items() if k not in exclude} \n",
    "# scores[\"RB\"] = rb_scores\n",
    "scores[\"LB\"] = lb_scores\n",
    "\n",
    "y = {key: [] for key in scores}\n",
    "k = 1\n",
    "best_scores = mb_scores[indices]\n",
    "for name, score in scores.items():\n",
    "    u = score[indices] if name in [\"LB\", \"Best\"] else score[k][indices]\n",
    "    y[name] = np.mean(u/best_scores)\n",
    "\n",
    "plt.figure(figsize=(5, 4))\n",
    "plt.bar(y.keys(), y.values(), zorder=5)\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.ylim((0.85, 0.96))\n",
    "plt.xticks(rotation=\"vertical\")\n",
    "# plt.legend(fontsize=8, loc= \"upper left\", bbox_to_anchor= (1, 1))\n",
    "plt.grid(axis=\"y\")\n",
    "plt.title(len(indices))\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"output/mean_acc2.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "indices = [i for i, y in enumerate(Y[selected_datasets]) if np.mean(1 - y[y>0]/max(y[y>0])) >= 0.]\n",
    "\n",
    "exclude = []\n",
    "scores = {k:v for k, v in model_scores.items() if k not in exclude} \n",
    "# scores[\"RB\"] = rb_scores\n",
    "scores[\"LB\"] = lb_scores\n",
    "\n",
    "y = {key: [] for key in scores}\n",
    "k = 5\n",
    "best_scores = mb_scores[indices]\n",
    "for name, score in scores.items():\n",
    "    u = score[indices] if name in [\"LB\", \"Best\"] else score[k][indices]\n",
    "    y[name] = u/best_scores\n",
    "\n",
    "plt.figure(figsize=(5, 4))\n",
    "plt.boxplot(y.values(), labels=y.keys())\n",
    "plt.ylabel(\"Accuracy\")\n",
    "# plt.ylim((0.67, 0.9))\n",
    "plt.xticks(rotation=\"vertical\")\n",
    "# plt.legend(fontsize=8, loc= \"upper left\", bbox_to_anchor= (1, 1))\n",
    "plt.grid(axis=\"y\")\n",
    "plt.title(len(indices))\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"output/mean_acc2.svg\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
