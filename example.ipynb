{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of a practical use case\n",
    "\n",
    "We present in this notebook a practical use case. Concretely, we will:\n",
    "1. Create a synthetic mixed dataset\n",
    "2. Compute the meta-features of the dataset\n",
    "3. Load one of the pre-trained meta-learners (namely _KNN_ for K-Medoids algorithm) and the scaler\n",
    "4. Predict the ranking of similarity measures pair (that can be computed on the dataset)\n",
    "5. Run the K-Medoids algorithm with the 5 top ranked pairs and compare their results with the literature baseline (*manhattan_hamming*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from mixed_metrics import get_valid_similarity_pairs\n",
    "from meta_features import compute_meta_features\n",
    "from sklearn.datasets import make_blobs\n",
    "from mixed_metrics import WeightedAverage\n",
    "from sklearn.preprocessing import OneHotEncoder, minmax_scale\n",
    "from base_metrics import get_available_metrics\n",
    "from kmedoids import fasterpam\n",
    "from experiments.utils import get_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a synthetic dataset\n",
    "\n",
    "We first create a numeric dataset using the `make_blobs` function in _scikit-learn_. Then, we transform some numeric attributes into categorical ones by discretizing their values.\n",
    "\n",
    "We also create a one-hot encoding representation of the categorical attributes that will be used by binary similarity measures. One-hot encoding consist in transforming each categorical attribute in several binary attributes, each one corresponding to one category of the transformed categorical attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discretize(x, n):\n",
    "    \"\"\"Discretize a list/array x by dividing its values into n intervals. \n",
    "    Each value in x is then associated with a category corresponding to one of the intervals.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : list / 1D array\n",
    "        The values to discretize\n",
    "    n : int\n",
    "        The number of categories\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    numpy array\n",
    "        The discretized values\n",
    "    \"\"\"\n",
    "    eps=1e-5\n",
    "    bins = np.linspace(min(x), max(x)+eps, n+1)\n",
    "    x_discrete = np.digitize(x, bins) - 1\n",
    "    permutation = np.random.permutation(n)\n",
    "    return permutation[x_discrete]\n",
    "\n",
    "# Create a synthetic dataset with the following parameters\n",
    "n_clusters = 5\n",
    "n_att = 3\n",
    "c_att = 7\n",
    "n_feats = n_att + c_att\n",
    "n_samples = 200\n",
    "\n",
    "# We use the make_blobs function in sklearn to create an initial dataset with the total number of features\n",
    "X, y = make_blobs(\n",
    "    centers=n_clusters,\n",
    "    n_samples=n_samples,\n",
    "    n_features=n_feats,\n",
    "    cluster_std=5,\n",
    "    random_state=0\n",
    ")\n",
    "y = y.flatten()\n",
    "\n",
    "# The we separate the numeric and categorical parts\n",
    "Xnum = X[:, :n_att]\n",
    "Xcat = np.zeros(shape=(n_samples, c_att))\n",
    "\n",
    "# Finally we discretize the categorical attributes\n",
    "for j in range(c_att):\n",
    "    n_cat = np.random.randint(2, 10)\n",
    "    Xcat[:, j] = discretize(X[:, n_att+j], n_cat)\n",
    "\n",
    "# We create the one hot encoding representation of the Xcat which will be used with binary similarity measures\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "Xdummy = enc.fit_transform(Xcat).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the meta-feature vector of the dataset\n",
    "\n",
    "To compute the meta-features vector, you can simply use the `compute_meta_features` function in [meta_features.py](meta_features.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Important: Normalize the numeric part before computing the meta-features or performing clustering\n",
    "Xnum = minmax_scale(Xnum)\n",
    "\n",
    "# create the meta-features vector of your dataset\n",
    "mf_vector = compute_meta_features(Xnum, Xcat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the pre-trained model and the scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the KNN model\n",
    "with open(\"models/KMedoids/KNN.pickle\", \"rb\") as f:\n",
    "    ranker = pickle.load(f)\n",
    "\n",
    "# load the scaler. The scaler is used to transform the meta-feature vector before passing it to the meta-learner.\n",
    "with open(\"models/KMedoids/scaler.pickle\", \"rb\") as f:\n",
    "    scaler = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict the ranking of the similarity measures pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cosine_eskin', 'sqeuclidean_co-oc', 'manhattan_jaccard', 'lorentzian_jaccard', 'chebyshev_jaccard']\n"
     ]
    }
   ],
   "source": [
    "# get the valid similarity measures pairs the dataset\n",
    "valid_pairs = get_valid_similarity_pairs(Xnum, Xcat)\n",
    "\n",
    "# predict the ranks/scores of all similarity measures pairs\n",
    "y_pred = ranker.predict(scaler.transform([mf_vector]))[0]\n",
    "\n",
    "# get a ranked list of similarity measures pairs\n",
    "ranked_pairs = ranker.similarity_pairs_[np.argsort(-y_pred)]\n",
    "\n",
    "# keep only valid similarity measures pairs for your dataset\n",
    "ranked_pairs = [sim_pair for sim_pair in ranked_pairs if sim_pair in valid_pairs]\n",
    "print(ranked_pairs[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for pair_name in ranked_pairs[:5]:\n",
    "#     print(pair_name)\n",
    "#     X = np.c_[Xnum, Xcat] if pair_name.split(\"_\")[1] in \\\n",
    "#         get_available_metrics(data_type=\"categorical\") else np.c_[Xnum, Xdummy]\n",
    "#     weights = np.linspace(0, 1, 11)\n",
    "#     plt.figure(figsize=(len(weights)*3, 3))\n",
    "#     for i, w in tqdm(enumerate(weights)):\n",
    "#         plt.subplot(1, len(weights), i+1)\n",
    "#         m = WeightedAverage(pair_name, w=w)\n",
    "#         m.fit(X, categorical=np.arange(Xnum.shape[1], X.shape[1]))\n",
    "#         D = m.pairwise(X, categorical=np.arange(Xnum.shape[1], X.shape[1]))\n",
    "#         Xemb = MDS(dissimilarity=\"precomputed\", normalized_stress=\"auto\").fit_transform(D)\n",
    "#         # Xemb = TSNE(metric=\"precomputed\", init='random').fit_transform(D)\n",
    "#         plt.scatter(Xemb[:,0], Xemb[:,1], c=y, s=30)\n",
    "#         plt.xticks([])\n",
    "#         plt.yticks([])\n",
    "#     plt.tight_layout(w_pad=0)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run K-Medoids with top ranked pairs and compare to the literature baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_kmedoids(D, n_clusters, n_init=10):\n",
    "    \"\"\"Run n_init times the K-Medoids algorithm with random initialization and return the result that minimize intra-cluster distances.\n",
    "    We consider the fasterpam version of K-Medoids implemented in the kmedoids library.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    D : 2D numpy array\n",
    "        The pairwise dissimilarity matrix\n",
    "    n_clusters : int\n",
    "        Number of clusters\n",
    "    n_init : int, optional\n",
    "        Number of random initialization, by default 10\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        The cluster labels of all samples\n",
    "    \"\"\"\n",
    "    final_clusters = None\n",
    "    best_score = np.inf\n",
    "    for random_state in range(n_init):\n",
    "        try:\n",
    "            res = fasterpam(D, n_clusters, random_state=random_state, n_cpu=1)\n",
    "            clusters = res.labels\n",
    "            score = res.loss\n",
    "            if score < best_score:\n",
    "                final_clusters = [val for val in clusters]\n",
    "        except:\n",
    "            print(f\"Error : k-medoids; random_state={random_state}\")\n",
    "    return final_clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We run K-Medoids using the literature baseline and the top ranked similarity measures pairs. For each pair we run the algorithm using different weights for the combination of the two similarity measures of the pair. We show the clustering accuracy score obtained with the best weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>manhattan_hamming</th>\n",
       "      <td>0.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cosine_eskin</th>\n",
       "      <td>0.590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sqeuclidean_co-oc</th>\n",
       "      <td>0.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>manhattan_jaccard</th>\n",
       "      <td>0.590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lorentzian_jaccard</th>\n",
       "      <td>0.605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chebyshev_jaccard</th>\n",
       "      <td>0.595</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    score\n",
       "manhattan_hamming   0.600\n",
       "cosine_eskin        0.590\n",
       "sqeuclidean_co-oc   0.740\n",
       "manhattan_jaccard   0.590\n",
       "lorentzian_jaccard  0.605\n",
       "chebyshev_jaccard   0.595"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_scores = []\n",
    "labels = [\"manhattan_hamming\"] + ranked_pairs[:5]\n",
    "\n",
    "# For each similarity measures pair\n",
    "for pair_name in labels:\n",
    "    # print(f\"{pair_name}:\", end=\" \")\n",
    "    X = np.c_[Xnum, Xcat] if pair_name.split(\"_\")[1] in \\\n",
    "        get_available_metrics(data_type=\"categorical\") else np.c_[Xnum, Xdummy]\n",
    "    weights = np.linspace(0, 1, 21)\n",
    "    scores = []\n",
    "    \n",
    "    # We run the algorithm for different weight\n",
    "    for i, w in enumerate(weights):\n",
    "        m = WeightedAverage(pair_name, w=w)\n",
    "        m.fit(X, categorical=np.arange(Xnum.shape[1], X.shape[1]))\n",
    "        D = m.pairwise(X, categorical=np.arange(Xnum.shape[1], X.shape[1]))\n",
    "        clusters = run_kmedoids(D, n_clusters=n_clusters)\n",
    "        scores.append(get_score(y, clusters, eval_metric=\"acc\"))\n",
    "\n",
    "    # We store the best accuracy score\n",
    "    best_score = max(scores)\n",
    "    # print(best_score)\n",
    "    best_scores.append(best_score)\n",
    "pd.DataFrame(index=labels, data=best_scores, columns=[\"score\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that in this use case, one of the top ranked pairs has an accuracy of 0.74 while the literature baseline has only 0.6"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
